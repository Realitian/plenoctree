{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# %load task_manager.py\n",
    "#  Copyright 2021 The PlenOctree Authors.\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer in the documentation\n",
    "#  and/or other materials provided with the distribution.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"\n",
    "Multi GPU parallel octree conversion pipeline for running hyper search.\n",
    "Make a file tasks.json describing tasks e.g.\n",
    "{\n",
    "\"data_root\": \"/home/sxyu/data\",\n",
    "\"train_root\": \"/home/sxyu/proj/jaxnerf/jaxnerf/train/SH16\",\n",
    "\"tasks\": [{\n",
    "        \"octree_name\": \"oct_chair_bb1_2\",\n",
    "        \"train_dir\": \"chair\",\n",
    "        \"data_dir\": \"nerf_synthetic/chair\",\n",
    "        \"config\": \"sh\",\n",
    "        \"extr_flags\": [\"--bbox_from_data\", \"--bbox_scale\", \"1.2\"],\n",
    "        \"opt_flags\": [],\n",
    "        \"eval_flags\": []\n",
    "    },\n",
    "    ...]\n",
    "}\n",
    "\n",
    "Then,\n",
    "python dispatch.py tasks.json --gpus='space delimited list of gpus to use'\n",
    "\n",
    "For each task, final octree is saved to\n",
    "<data_root>/<data_dir>/octrees/<octree_name>/tree.npz\n",
    "If you specify --keep_raw, the above is raw tree and the optimized tree is saved to\n",
    "<data_root>/<data_dir>/octrees/<octree_name>/tree_opt.npz\n",
    "\n",
    "Capacity, raw eval PSNR/SSIM/LPIPS, optimized eval PSNR/SSIM/LPIPS are saved to\n",
    "<data_root>/<data_dir>/octrees/<octree_name>/results.txt\n",
    "\"\"\"\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "import json\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"task_json\", type=str)\n",
    "parser.add_argument(\"--gpus\", type=str, required=True,\n",
    "                    help=\"space delimited GPU id list (pre CUDA_VISIBLE_DEVICES)\")\n",
    "parser.add_argument(\"--keep_raw\", action='store_true',\n",
    "        help=\"do not overwrite raw octree (takes extra disk space)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "def convert_one(env, train_dir, data_dir, config, octree_name,\n",
    "                extr_flags, opt_flags=[], eval_flags=[]):\n",
    "    octree_store_dir = osp.join(train_dir, 'octrees', octree_name)\n",
    "    octree_file = osp.join(octree_store_dir, \"tree.npz\")\n",
    "    octree_opt_file = osp.join(octree_store_dir,\n",
    "            \"tree_opt.npz\") if args.keep_raw else octree_file\n",
    "    config_name = f\"{config}\"\n",
    "    os.makedirs(octree_store_dir, exist_ok=True)\n",
    "    extr_base_cmd = [\n",
    "        \"python\", \"-u\", \"-m\", \"octree.extraction\",\n",
    "        \"--train_dir\", train_dir,\n",
    "        \"--config\", config_name, \"--is_jaxnerf_ckpt\",\n",
    "        \"--output \", octree_file,\n",
    "        \"--data_dir\", data_dir\n",
    "    ]\n",
    "    opt_base_cmd = [\n",
    "        \"python\", \"-u\", \"-m\", \"octree.optimization\",\n",
    "        \"--config\", config_name, \"--input\", octree_file,\n",
    "        \"--output\", octree_opt_file,\n",
    "        \"--data_dir\", data_dir\n",
    "    ]\n",
    "    eval_base_cmd = [\n",
    "        \"python\", \"-u\", \"-m\", \"octree.evaluation\",\n",
    "        \"--config\", config_name, \"--input \", octree_opt_file,\n",
    "        \"--data_dir\", data_dir\n",
    "    ]\n",
    "    out_file_path = osp.join(octree_store_dir, 'results.txt')\n",
    "\n",
    "    with open(out_file_path, 'w') as out_file:\n",
    "        print('********************************************')\n",
    "        print('! Extract', train_dir, octree_name)\n",
    "        extr_cmd = ' '.join(extr_base_cmd + extr_flags)\n",
    "        print(extr_cmd)\n",
    "        extr_ret = subprocess.check_output(extr_cmd, shell=True, env=env).decode(\n",
    "                sys.stdout.encoding)\n",
    "        with open('pextract.txt', 'w') as f:\n",
    "            f.write(extr_ret)\n",
    "\n",
    "        extr_ret = extr_ret.split('\\n')\n",
    "        svox_str = extr_ret[-9]\n",
    "        capacity = int(svox_str.split()[3].split(':')[1].split('/')[0])\n",
    "\n",
    "        parse_metrics = lambda x: map(float, x.split()[2::2])\n",
    "        psnr, ssim, lpips = parse_metrics(extr_ret[-2])\n",
    "        print(': ', octree_name, 'RAW capacity',\n",
    "              capacity, 'PSNR', psnr, 'SSIM', ssim, 'LPIPS', lpips)\n",
    "        out_file.write(f'{capacity}\\n{psnr:.10f} {ssim:.10f} {lpips:.10f}\\n')\n",
    "\n",
    "        print('! Optimize', train_dir, octree_name)\n",
    "        opt_cmd = ' '.join(opt_base_cmd + opt_flags)\n",
    "        print(opt_cmd)\n",
    "        subprocess.call(opt_cmd, shell=True, env=env)\n",
    "\n",
    "        if osp.exists(octree_opt_file):\n",
    "            print('! Eval', train_dir, octree_name)\n",
    "            eval_cmd = ' '.join(eval_base_cmd + eval_flags)\n",
    "            print(eval_cmd)\n",
    "            eval_ret = subprocess.check_output(eval_cmd, shell=True, env=env).decode(\n",
    "                    sys.stdout.encoding)\n",
    "            eval_ret = eval_ret.split('\\n')\n",
    "\n",
    "            epsnr, essim, elpips = parse_metrics(eval_ret[-2])\n",
    "            print(':', octree_name, 'OPT capacity',\n",
    "                  capacity, 'PSNR', epsnr, 'SSIM', essim, 'LPIPS', elpips)\n",
    "            out_file.write(f'{epsnr:.10f} {essim:.10f} {elpips:.10f}\\n')\n",
    "        else:\n",
    "            print('! Eval skipped')\n",
    "            out_file.write(f'{psnr:.10f} {ssim:.10f} {lpips:.10f}\\n')\n",
    "\n",
    "\n",
    "\n",
    "def process_main(device, queue):\n",
    "    # Set CUDA_VISIBLE_DEVICES programmatically\n",
    "    env = os.environ.copy()\n",
    "    env[\"CUDA_VISIBLE_DEVICES\"] = str(device)\n",
    "    while True:\n",
    "        task = queue.get()\n",
    "        if len(task) == 0:\n",
    "            break\n",
    "        convert_one(env, **task)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    with open(args.task_json, 'r') as f:\n",
    "        tasks_file = json.load(f)\n",
    "    all_tasks = tasks_file.get('tasks', [])\n",
    "    data_root = tasks_file['data_root']\n",
    "    train_root = tasks_file['train_root']\n",
    "    pqueue = Queue()\n",
    "    # Scene_tasks generated per scene (use {%} to mean scene name)\n",
    "    if 'scene_tasks' in tasks_file:\n",
    "        symb = '{%}'\n",
    "        scenes = tasks_file['scenes']\n",
    "        for scene_task in tasks_file['scene_tasks']:\n",
    "            for scene in scenes:\n",
    "                task = scene_task.copy()\n",
    "                task['data_dir'] = scene_task['data_dir'].replace(symb, scene)\n",
    "                task['train_dir'] = scene_task['train_dir'].replace(symb, scene)\n",
    "                task['octree_name'] = scene_task['octree_name'].replace(symb, scene)\n",
    "                all_tasks.append(task)\n",
    "\n",
    "    print(len(all_tasks), 'total tasks')\n",
    "\n",
    "    for task in all_tasks:\n",
    "        task['train_dir'] = osp.join(train_root, task['train_dir'])\n",
    "        task['data_dir'] = osp.join(data_root, task['data_dir'])\n",
    "        octrees_dir = osp.join(task['data_dir'], 'octrees')\n",
    "        os.makedirs(octrees_dir, exist_ok=True)\n",
    "        # santity check\n",
    "        assert os.path.exists(task['train_dir']), task['train_dir']\n",
    "        assert os.path.exists(task['data_dir']), task['data_dir']\n",
    "\n",
    "    for task in all_tasks:\n",
    "        pqueue.put(task)\n",
    "    pqueue.put({})\n",
    "\n",
    "    args.gpus = list(map(int, args.gpus.split()))\n",
    "    print('GPUS:', args.gpus)\n",
    "\n",
    "    all_procs = []\n",
    "    for i, gpu in enumerate(args.gpus):\n",
    "        process = Process(target=process_main, args=(gpu, pqueue))\n",
    "        process.daemon = True\n",
    "        process.start()\n",
    "        all_procs.append(process)\n",
    "\n",
    "    for i, gpu in enumerate(args.gpus):\n",
    "        all_procs[i].join()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}