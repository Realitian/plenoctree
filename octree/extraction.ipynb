{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# %load extraction.py\n",
    "#  Copyright 2021 The PlenOctree Authors.\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer in the documentation\n",
    "#  and/or other materials provided with the distribution.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"Extract a plenoctree from a trained NeRF-SH model.\n",
    "\n",
    "Usage:\n",
    "\n",
    "export DATA_ROOT=./data/NeRF/nerf_synthetic/\n",
    "export CKPT_ROOT=./data/PlenOctree/checkpoints/syn_sh16\n",
    "export SCENE=chair\n",
    "export CONFIG_FILE=nerf_sh/config/blender\n",
    "\n",
    "python -m octree.extraction \\\n",
    "    --train_dir $CKPT_ROOT/$SCENE/ --is_jaxnerf_ckpt \\\n",
    "    --config $CONFIG_FILE \\\n",
    "    --data_dir $DATA_ROOT/$SCENE/ \\\n",
    "    --output $CKPT_ROOT/$SCENE/octrees/tree.npz\n",
    "\"\"\"\n",
    "import os\n",
    "# Get rid of ugly TF logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "from octree.nerf import models\n",
    "from octree.nerf import utils\n",
    "from octree.nerf import datasets\n",
    "from octree.nerf import sh_proj\n",
    "\n",
    "from svox import N3Tree\n",
    "from svox import NDCConfig, VolumeRenderer\n",
    "from svox.helpers import _get_c_extension\n",
    "from tqdm import tqdm\n",
    "\n",
    "_C = _get_c_extension()\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "utils.define_flags()\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output\",\n",
    "    \"./tree.npz\",\n",
    "    \"Output file\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"center\",\n",
    "    \"0 0 0\",\n",
    "    \"Center of volume in x y z OR single number\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"radius\",\n",
    "    \"1.5\",\n",
    "    \"1/2 side length of volume\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"alpha_thresh\",\n",
    "    0.01,\n",
    "    \"Alpha threshold to keep a voxel in initial sigma thresholding\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"max_refine_prop\",\n",
    "    0.5,\n",
    "    \"Max proportion of cells to refine\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"z_min\",\n",
    "    None,\n",
    "    \"Discard z axis points below this value, for NDC use\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"z_max\",\n",
    "    None,\n",
    "    \"Discard z axis points above this value, for NDC use\",\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    \"tree_branch_n\",\n",
    "    2,\n",
    "    \"Tree branch factor (2=octree)\",\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    \"init_grid_depth\",\n",
    "    8,\n",
    "    \"Initial evaluation grid (2^{x+1} voxel grid)\",\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    \"samples_per_cell\",\n",
    "    8,\n",
    "    \"Samples per cell in step 2 (3D antialiasing)\",\n",
    "    short_name='S',\n",
    ")\n",
    "flags.DEFINE_bool(\n",
    "    \"is_jaxnerf_ckpt\",\n",
    "    False,\n",
    "    \"Whether the ckpt is from jaxnerf or not.\",\n",
    ")\n",
    "flags.DEFINE_enum(\n",
    "    \"masking_mode\",\n",
    "    \"weight\",\n",
    "    [\"sigma\", \"weight\"],\n",
    "    \"How to calculate mask when building the octree\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"weight_thresh\",\n",
    "    0.001,\n",
    "    \"Weight threshold to keep a voxel\",\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    \"projection_samples\",\n",
    "    10000,\n",
    "    \"Number of rays to sample for SH projection.\",\n",
    ")\n",
    "\n",
    "# Load bbox from dataset\n",
    "flags.DEFINE_bool(\n",
    "    \"bbox_from_data\",\n",
    "    False,\n",
    "    \"Use bounding box from dataset if possible\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"data_bbox_scale\",\n",
    "    1.0,\n",
    "    \"Scaling factor to apply to the bounding box from dataset (before autoscale), \" +\n",
    "    \"if bbox_from_data is used\",\n",
    ")\n",
    "flags.DEFINE_bool(\n",
    "    \"autoscale\",\n",
    "    False,\n",
    "    \"Automatic scaling, after bbox_from_data\",\n",
    ")\n",
    "flags.DEFINE_bool(\n",
    "    \"bbox_cube\",\n",
    "    False,\n",
    "    \"Force bbox to be a cube\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"bbox_scale\",\n",
    "    1.0,\n",
    "    \"Scaling factor to apply to the bounding box at the end (after load, autoscale)\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"scale_alpha_thresh\",\n",
    "    0.01,\n",
    "    \"Alpha threshold to keep a voxel in initial sigma thresholding for autoscale\",\n",
    ")\n",
    "# For integrated eval (to avoid slow load)\n",
    "flags.DEFINE_bool(\n",
    "    \"eval\",\n",
    "    True,\n",
    "    \"Evaluate after building the octree\",\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def calculate_grid_weights(dataset, sigmas, reso, invradius, offset):\n",
    "    w, h, focal = dataset.w, dataset.h, dataset.focal\n",
    "\n",
    "    opts = _C.RenderOptions()\n",
    "    opts.step_size = FLAGS.renderer_step_size\n",
    "    opts.sigma_thresh = 0.0\n",
    "    if 'llff' in FLAGS.config and (not FLAGS.spherify):\n",
    "        ndc_config = NDCConfig(width=w, height=h, focal=focal)\n",
    "        opts.ndc_width = ndc_config.width\n",
    "        opts.ndc_height = ndc_config.height\n",
    "        opts.ndc_focal = ndc_config.focal\n",
    "    else:\n",
    "        opts.ndc_width = -1\n",
    "\n",
    "    cam = _C.CameraSpec()\n",
    "    cam.fx = focal\n",
    "    cam.fy = focal\n",
    "    cam.width = w\n",
    "    cam.height = h\n",
    "\n",
    "    grid_data = sigmas.reshape((reso, reso, reso))\n",
    "    maximum_weight = torch.zeros_like(grid_data)\n",
    "    for idx in tqdm(range(dataset.size)):\n",
    "        cam.c2w = torch.from_numpy(dataset.camtoworlds[idx]).float().to(sigmas.device)\n",
    "        grid_weight, grid_hit = _C.grid_weight_render(\n",
    "            grid_data,\n",
    "            cam,\n",
    "            opts,\n",
    "            offset,\n",
    "            invradius,\n",
    "        )\n",
    "        maximum_weight = torch.max(maximum_weight, grid_weight)\n",
    "\n",
    "    return maximum_weight\n",
    "\n",
    "\n",
    "def project_nerf_to_sh(nerf, sh_deg, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points: [N, 3]\n",
    "    Returns:\n",
    "        coeffs for rgb. [N, C * (sh_deg + 1)**2]\n",
    "    \"\"\"\n",
    "    nerf.use_viewdirs = True\n",
    "\n",
    "    def _sperical_func(viewdirs):\n",
    "        # points: [num_points, 3]\n",
    "        # viewdirs: [num_rays, 3]\n",
    "        # raw_rgb: [num_points, num_rays, 3]\n",
    "        # sigma: [num_points]\n",
    "        raw_rgb, sigma = nerf.eval_points_raw(points, viewdirs, cross_broadcast=True)\n",
    "        return raw_rgb, sigma\n",
    "\n",
    "    coeffs, sigma = sh_proj.ProjectFunctionNeRF(\n",
    "        order=sh_deg,\n",
    "        sperical_func=_sperical_func,\n",
    "        batch_size=points.shape[0],\n",
    "        sample_count=FLAGS.projection_samples,\n",
    "        device=points.device)\n",
    "\n",
    "    return coeffs.reshape([points.shape[0], -1]), sigma\n",
    "\n",
    "\n",
    "def auto_scale(args, center, radius, nerf):\n",
    "    print('* Step 0: Auto scale')\n",
    "    reso = 2 ** args.init_grid_depth\n",
    "\n",
    "    radius = torch.tensor(radius, dtype=torch.float32)\n",
    "    center = torch.tensor(center, dtype=torch.float32)\n",
    "    scale = 0.5 / radius\n",
    "    offset = 0.5 * (1.0 - center / radius)\n",
    "\n",
    "    arr = (torch.arange(0, reso, dtype=torch.float32) + 0.5) / reso\n",
    "    xx = (arr - offset[0]) / scale[0]\n",
    "    yy = (arr - offset[1]) / scale[1]\n",
    "    zz = (arr - offset[2]) / scale[2]\n",
    "    if args.z_min is not None:\n",
    "        zz = zz[zz >= args.z_min]\n",
    "    if args.z_max is not None:\n",
    "        zz = zz[zz <= args.z_max]\n",
    "\n",
    "    grid = torch.stack(torch.meshgrid(xx, yy, zz)).reshape(3, -1).T\n",
    "\n",
    "    out_chunks = []\n",
    "    for i in tqdm(range(0, grid.shape[0], args.chunk)):\n",
    "        grid_chunk = grid[i:i+args.chunk].cuda()\n",
    "        if nerf.use_viewdirs:\n",
    "            fake_viewdirs = torch.zeros([grid_chunk.shape[0], 3], device=grid_chunk.device)\n",
    "        else:\n",
    "            fake_viewdirs = None\n",
    "        rgb, sigma = nerf.eval_points_raw(grid_chunk, fake_viewdirs)\n",
    "        del grid_chunk\n",
    "        out_chunks.append(sigma.squeeze(-1))\n",
    "    sigmas = torch.cat(out_chunks, 0)\n",
    "    del out_chunks\n",
    "\n",
    "    approx_delta = 2.0 / reso\n",
    "    sigma_thresh = -np.log(1.0 - args.scale_alpha_thresh) / approx_delta\n",
    "    mask = sigmas >= sigma_thresh\n",
    "\n",
    "    grid = grid[mask]\n",
    "    del mask\n",
    "\n",
    "    lc = grid.min(dim=0)[0] - 0.5 / reso\n",
    "    uc = grid.max(dim=0)[0] + 0.5 / reso\n",
    "    return ((lc + uc) * 0.5).tolist(), ((uc - lc) * 0.5).tolist()\n",
    "\n",
    "def step1(args, tree, nerf, dataset):\n",
    "    print('* Step 1: Grid eval')\n",
    "    reso = 2 ** (args.init_grid_depth + 1)\n",
    "    offset = tree.offset.cpu()\n",
    "    scale = tree.invradius.cpu()\n",
    "\n",
    "    arr = (torch.arange(0, reso, dtype=torch.float32) + 0.5) / reso\n",
    "    xx = (arr - offset[0]) / scale[0]\n",
    "    yy = (arr - offset[1]) / scale[1]\n",
    "    zz = (arr - offset[2]) / scale[2]\n",
    "    if args.z_min is not None:\n",
    "        zz = zz[zz >= args.z_min]\n",
    "    if args.z_max is not None:\n",
    "        zz = zz[zz <= args.z_max]\n",
    "\n",
    "    grid = torch.stack(torch.meshgrid(xx, yy, zz)).reshape(3, -1).T\n",
    "    print('init grid', grid.shape)\n",
    "\n",
    "    approx_delta = 2.0 / reso\n",
    "    sigma_thresh = -np.log(1.0 - args.alpha_thresh) / approx_delta\n",
    "\n",
    "    out_chunks = []\n",
    "    for i in tqdm(range(0, grid.shape[0], args.chunk)):\n",
    "        grid_chunk = grid[i:i+args.chunk].cuda()\n",
    "        if nerf.use_viewdirs:\n",
    "            fake_viewdirs = torch.zeros([grid_chunk.shape[0], 3], device=grid_chunk.device)\n",
    "        else:\n",
    "            fake_viewdirs = None\n",
    "        rgb, sigma = nerf.eval_points_raw(grid_chunk, fake_viewdirs)\n",
    "        del grid_chunk\n",
    "        out_chunks.append(sigma.squeeze(-1))\n",
    "    sigmas = torch.cat(out_chunks, 0)\n",
    "    del out_chunks\n",
    "\n",
    "    if FLAGS.masking_mode == \"sigma\":\n",
    "        mask = sigmas >= sigma_thresh\n",
    "    elif FLAGS.masking_mode == \"weight\":\n",
    "        print (\"* Calculating grid weights\")\n",
    "        grid_weights = calculate_grid_weights(dataset,\n",
    "            sigmas, reso, tree.invradius, tree.offset)\n",
    "        mask = grid_weights.reshape(-1) >= FLAGS.weight_thresh\n",
    "        del grid_weights\n",
    "    else:\n",
    "        raise ValueError\n",
    "    del sigmas\n",
    "\n",
    "    grid = grid[mask]\n",
    "    del mask\n",
    "    print(grid.shape, grid.min(), grid.max())\n",
    "    grid = grid.cuda()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(' Building octree')\n",
    "    for i in range(args.init_grid_depth - 1):\n",
    "        tree[grid].refine()\n",
    "    refine_chunk = 2000000\n",
    "    if grid.shape[0] <= refine_chunk:\n",
    "        tree[grid].refine()\n",
    "    else:\n",
    "        # Do last layer separately\n",
    "        grid = grid.cpu()\n",
    "        for j in tqdm(range(0, grid.shape[0], refine_chunk)):\n",
    "            tree[grid[j:j+refine_chunk].cuda()].refine()\n",
    "    print(tree)\n",
    "\n",
    "    assert tree.max_depth == args.init_grid_depth\n",
    "\n",
    "def step2(args, tree, nerf):\n",
    "    print('* Step 2: AA', args.samples_per_cell)\n",
    "\n",
    "    leaf_mask = tree.depths.cpu() == tree.max_depth\n",
    "    leaf_ind = torch.where(leaf_mask)[0]\n",
    "    del leaf_mask\n",
    "\n",
    "    if args.use_viewdirs:\n",
    "        chunk_size = args.chunk // (args.samples_per_cell * args.projection_samples // 10)\n",
    "    else:\n",
    "        chunk_size = args.chunk // (args.samples_per_cell)\n",
    "\n",
    "    for i in tqdm(range(0, leaf_ind.size(0), chunk_size)):\n",
    "        chunk_inds = leaf_ind[i:i+chunk_size]\n",
    "        points = tree[chunk_inds].sample(args.samples_per_cell)  # (n_cells, n_samples, 3)\n",
    "        points = points.view(-1, 3)\n",
    "\n",
    "        if not args.use_viewdirs:  # trained NeRF-SH/SG model returns rgb as coeffs\n",
    "            rgb, sigma = nerf.eval_points_raw(points)\n",
    "        else:  # vanilla NeRF model returns rgb, so we project them into coeffs (only SH supported)\n",
    "            rgb, sigma = project_nerf_to_sh(nerf, args.sh_deg, points)\n",
    "\n",
    "        rgba = torch.cat([rgb, sigma], dim=-1)\n",
    "        del rgb, sigma\n",
    "        rgba = rgba.reshape(-1, args.samples_per_cell, tree.data_dim).mean(dim=1)\n",
    "        tree[chunk_inds] = rgba\n",
    "\n",
    "def euler2mat(angle):\n",
    "    \"\"\"Convert euler angles to rotation matrix.\n",
    "\n",
    "    Args:\n",
    "        angle: rotation angle along 3 axis (in radians). [..., 3]\n",
    "    Returns:\n",
    "        Rotation matrix corresponding to the euler angles. [..., 3, 3]\n",
    "    \"\"\"\n",
    "    x, y, z = angle[..., 0], angle[..., 1], angle[..., 2]\n",
    "    cosz = torch.cos(z)\n",
    "    sinz = torch.sin(z)\n",
    "    cosy = torch.cos(y)\n",
    "    siny = torch.sin(y)\n",
    "    cosx = torch.cos(x)\n",
    "    sinx = torch.sin(x)\n",
    "    zeros = torch.zeros_like(z)\n",
    "    ones = torch.ones_like(z)\n",
    "    zmat = torch.stack([torch.stack([cosz,  -sinz, zeros], dim=-1),\n",
    "                        torch.stack([sinz,   cosz, zeros], dim=-1),\n",
    "                        torch.stack([zeros, zeros,  ones], dim=-1)], dim=-1)\n",
    "    ymat = torch.stack([torch.stack([ cosy, zeros,  siny], dim=-1),\n",
    "                        torch.stack([zeros,  ones, zeros], dim=-1),\n",
    "                        torch.stack([-siny, zeros,  cosy], dim=-1)], dim=-1)\n",
    "    xmat = torch.stack([torch.stack([ ones, zeros, zeros], dim=-1),\n",
    "                        torch.stack([zeros,  cosx, -sinx], dim=-1),\n",
    "                        torch.stack([zeros,  sinx,  cosx], dim=-1)], dim=-1)\n",
    "    rotMat = torch.einsum(\"...ij,...jk,...kq->...iq\", xmat, ymat, zmat)\n",
    "    return rotMat\n",
    "\n",
    "@torch.no_grad()\n",
    "def main(unused_argv):\n",
    "    utils.set_random_seed(20200823)\n",
    "    utils.update_flags(FLAGS)\n",
    "\n",
    "    print('* Loading NeRF')\n",
    "    nerf = models.get_model_state(FLAGS, device=device, restore=True)\n",
    "    nerf.eval()\n",
    "\n",
    "    data_format = None\n",
    "    extra_data = None\n",
    "    if FLAGS.sg_dim > 0:\n",
    "        data_format = f'SG{FLAGS.sg_dim}'\n",
    "        assert FLAGS.sg_global\n",
    "        extra_data = torch.cat((\n",
    "                            F.softplus(nerf.sg_lambda[:, None]),\n",
    "                            sh_proj.spher2cart(nerf.sg_mu_spher[:, 0], nerf.sg_mu_spher[:, 1])\n",
    "                         ), dim=-1)\n",
    "    elif FLAGS.sh_deg > 0:\n",
    "        data_format = f'SH{(FLAGS.sh_deg + 1) ** 2}'\n",
    "    if data_format is not None:\n",
    "        print('Detected format:', data_format)\n",
    "\n",
    "    base_dir = osp.dirname(FLAGS.output)\n",
    "    if base_dir:\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    assert FLAGS.data_dir  # Dataset is required now\n",
    "    dataset = datasets.get_dataset(\"train\", FLAGS)\n",
    "\n",
    "    if FLAGS.bbox_from_data:\n",
    "        assert dataset.bbox is not None  # Dataset must be NSVF\n",
    "        center = (dataset.bbox[:3] + dataset.bbox[3:6]) * 0.5\n",
    "        radius = (dataset.bbox[3:6] - dataset.bbox[:3]) * 0.5 * FLAGS.data_bbox_scale\n",
    "        print('Bounding box from data: c', center, 'r', radius)\n",
    "    else:\n",
    "        center = list(map(float, FLAGS.center.split()))\n",
    "        if len(center) == 1:\n",
    "            center *= 3\n",
    "        radius = list(map(float, FLAGS.radius.split()))\n",
    "        if len(radius) == 1:\n",
    "            radius *= 3\n",
    "\n",
    "    if FLAGS.autoscale:\n",
    "        center, radius = auto_scale(FLAGS, center, radius, nerf)\n",
    "        print('Autoscale result center', center, 'radius', radius)\n",
    "\n",
    "    radius = [r * FLAGS.bbox_scale for r in radius]\n",
    "    if FLAGS.bbox_cube:\n",
    "        radius = [max(radius)] * 3\n",
    "\n",
    "    num_rgb_channels = FLAGS.num_rgb_channels\n",
    "    if FLAGS.sh_deg >= 0:\n",
    "        assert FLAGS.sg_dim == -1, (\n",
    "            \"You can only use up to one of: SH or SG\")\n",
    "        num_rgb_channels *= (FLAGS.sh_deg + 1) ** 2\n",
    "    elif FLAGS.sg_dim > 0:\n",
    "        assert FLAGS.sh_deg == -1, (\n",
    "            \"You can only use up to one of: SH or SG\")\n",
    "        num_rgb_channels *= FLAGS.sg_dim\n",
    "    data_dim =  1 + num_rgb_channels  # alpha + rgb\n",
    "    print('data dim is', data_dim)\n",
    "\n",
    "    print('* Creating model')\n",
    "    tree = N3Tree(N=FLAGS.tree_branch_n,\n",
    "                  data_dim=data_dim,\n",
    "                  init_refine=0,\n",
    "                  init_reserve=500000,\n",
    "                  geom_resize_fact=1.0,\n",
    "                  depth_limit=FLAGS.init_grid_depth,\n",
    "                  radius=radius,\n",
    "                  center=center,\n",
    "                  data_format=data_format,\n",
    "                  extra_data=extra_data,\n",
    "                  map_location=device)\n",
    "\n",
    "    step1(FLAGS, tree, nerf, dataset)\n",
    "    step2(FLAGS, tree, nerf)\n",
    "    tree[:, -1:].relu_()\n",
    "    tree.shrink_to_fit()\n",
    "    print(tree)\n",
    "\n",
    "    del dataset.images\n",
    "    print('* Saving', FLAGS.output)\n",
    "    tree.save(FLAGS.output, compress=False)  # Faster saving\n",
    "\n",
    "    if FLAGS.eval:\n",
    "        dataset = datasets.get_dataset(\"test\", FLAGS)\n",
    "        print('* Evaluation (before fine tune)')\n",
    "        avg_psnr, avg_ssim, avg_lpips, out_frames = utils.eval_octree(tree,\n",
    "                dataset, FLAGS, want_lpips=True)\n",
    "        print('Average PSNR', avg_psnr, 'SSIM', avg_ssim, 'LPIPS', avg_lpips)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(main)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}