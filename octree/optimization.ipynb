{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# %load optimization.py\n",
    "#  Copyright 2021 The PlenOctree Authors.\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#  this list of conditions and the following disclaimer in the documentation\n",
    "#  and/or other materials provided with the distribution.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"Optimize a plenoctree through finetuning on train set.\n",
    "\n",
    "Usage:\n",
    "\n",
    "export DATA_ROOT=./data/NeRF/nerf_synthetic/\n",
    "export CKPT_ROOT=./data/PlenOctree/checkpoints/syn_sh16\n",
    "export SCENE=chair\n",
    "export CONFIG_FILE=nerf_sh/config/blender\n",
    "\n",
    "python -m octree.optimization \\\n",
    "    --input $CKPT_ROOT/$SCENE/tree.npz \\\n",
    "    --config $CONFIG_FILE \\\n",
    "    --data_dir $DATA_ROOT/$SCENE/ \\\n",
    "    --output $CKPT_ROOT/$SCENE/octrees/tree_opt.npz\n",
    "\"\"\"\n",
    "import svox\n",
    "import torch\n",
    "import torch.cuda\n",
    "import numpy as np\n",
    "import json\n",
    "import imageio\n",
    "import os.path as osp\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm\n",
    "from torch.optim import SGD, Adam\n",
    "from warnings import warn\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "from octree.nerf import datasets\n",
    "from octree.nerf import utils\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "utils.define_flags()\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"input\",\n",
    "    \"./tree.npz\",\n",
    "    \"Input octree npz from extraction.py\",\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    \"output\",\n",
    "    \"./tree_opt.npz\",\n",
    "    \"Output octree npz\",\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'render_interval',\n",
    "    0,\n",
    "    'render interval')\n",
    "flags.DEFINE_integer(\n",
    "    'val_interval',\n",
    "    2,\n",
    "    'validation interval')\n",
    "flags.DEFINE_integer(\n",
    "    'num_epochs',\n",
    "    80,\n",
    "    'epochs to train for')\n",
    "flags.DEFINE_bool(\n",
    "    'sgd',\n",
    "    True,\n",
    "    'use SGD optimizer instead of Adam')\n",
    "flags.DEFINE_float(\n",
    "    'lr',\n",
    "    1e7,\n",
    "    'optimizer step size')\n",
    "flags.DEFINE_float(\n",
    "    'sgd_momentum',\n",
    "    0.0,\n",
    "    'sgd momentum')\n",
    "flags.DEFINE_bool(\n",
    "    'sgd_nesterov',\n",
    "    False,\n",
    "    'sgd nesterov momentum?')\n",
    "flags.DEFINE_string(\n",
    "    \"write_vid\",\n",
    "    None,\n",
    "    \"If specified, writes rendered video to given path (*.mp4)\",\n",
    ")\n",
    "\n",
    "# Manual 'val' set\n",
    "flags.DEFINE_bool(\n",
    "    \"split_train\",\n",
    "    None,\n",
    "    \"If specified, splits train set instead of loading val set\",\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    \"split_holdout_prop\",\n",
    "    0.2,\n",
    "    \"Proportion of images to hold out if split_train is set\",\n",
    ")\n",
    "\n",
    "# Do not save since it is slow\n",
    "flags.DEFINE_bool(\n",
    "    \"nosave\",\n",
    "    False,\n",
    "    \"If set, does not save (for speed)\",\n",
    ")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"continue_on_decrease\",\n",
    "    False,\n",
    "    \"If set, continues training even if validation PSNR decreases\",\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    utils.set_random_seed(20200823)\n",
    "    utils.update_flags(FLAGS)\n",
    "\n",
    "    def get_data(stage):\n",
    "        assert stage in [\"train\", \"val\", \"test\"]\n",
    "        dataset = datasets.get_dataset(stage, FLAGS)\n",
    "        focal = dataset.focal\n",
    "        all_c2w = dataset.camtoworlds\n",
    "        all_gt = dataset.images.reshape(-1, dataset.h, dataset.w, 3)\n",
    "        all_c2w = torch.from_numpy(all_c2w).float().to(device)\n",
    "        all_gt = torch.from_numpy(all_gt).float()\n",
    "        return focal, all_c2w, all_gt\n",
    "\n",
    "    focal, train_c2w, train_gt = get_data(\"train\")\n",
    "    if FLAGS.split_train:\n",
    "        test_sz = int(train_c2w.size(0) * FLAGS.split_holdout_prop)\n",
    "        print('Splitting train to train/val manually, holdout', test_sz)\n",
    "        perm = torch.randperm(train_c2w.size(0))\n",
    "        test_c2w = train_c2w[perm[:test_sz]]\n",
    "        test_gt = train_gt[perm[:test_sz]]\n",
    "        train_c2w = train_c2w[perm[test_sz:]]\n",
    "        train_gt = train_gt[perm[test_sz:]]\n",
    "    else:\n",
    "        print('Using given val set')\n",
    "        test_focal, test_c2w, test_gt = get_data(\"val\")\n",
    "        assert focal == test_focal\n",
    "    H, W = train_gt[0].shape[:2]\n",
    "\n",
    "    vis_dir = osp.splitext(FLAGS.input)[0] + '_render'\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "    print('N3Tree load')\n",
    "    t = svox.N3Tree.load(FLAGS.input, map_location=device)\n",
    "    #  t.nan_to_num_()\n",
    "\n",
    "    if 'llff' in FLAGS.config:\n",
    "        ndc_config = svox.NDCConfig(width=W, height=H, focal=focal)\n",
    "    else:\n",
    "        ndc_config = None\n",
    "    r = svox.VolumeRenderer(t, step_size=FLAGS.renderer_step_size, ndc=ndc_config)\n",
    "\n",
    "    if FLAGS.sgd:\n",
    "        print('Using SGD, lr', FLAGS.lr)\n",
    "        if FLAGS.lr < 1.0:\n",
    "            warn('For SGD please adjust LR to about 1e7')\n",
    "        optimizer = SGD(t.parameters(), lr=FLAGS.lr, momentum=FLAGS.sgd_momentum,\n",
    "                        nesterov=FLAGS.sgd_nesterov)\n",
    "    else:\n",
    "        adam_eps = 1e-4 if t.data.dtype is torch.float16 else 1e-8\n",
    "        print('Using Adam, eps', adam_eps, 'lr', FLAGS.lr)\n",
    "        optimizer = Adam(t.parameters(), lr=FLAGS.lr, eps=adam_eps)\n",
    "\n",
    "    n_train_imgs = len(train_c2w)\n",
    "    n_test_imgs = len(test_c2w)\n",
    "\n",
    "    def run_test_step(i):\n",
    "        print('Evaluating')\n",
    "        with torch.no_grad():\n",
    "            tpsnr = 0.0\n",
    "            for j, (c2w, im_gt) in enumerate(zip(test_c2w, test_gt)):\n",
    "                im = r.render_persp(c2w, height=H, width=W, fx=focal, fast=False)\n",
    "                im = im.cpu().clamp_(0.0, 1.0)\n",
    "\n",
    "                mse = ((im - im_gt) ** 2).mean()\n",
    "                psnr = -10.0 * np.log(mse) / np.log(10.0)\n",
    "                tpsnr += psnr.item()\n",
    "\n",
    "                if FLAGS.render_interval > 0 and j % FLAGS.render_interval == 0:\n",
    "                    vis = torch.cat((im_gt, im), dim=1)\n",
    "                    vis = (vis * 255).numpy().astype(np.uint8)\n",
    "                    imageio.imwrite(f\"{vis_dir}/{i:04}_{j:04}.png\", vis)\n",
    "            tpsnr /= n_test_imgs\n",
    "            return tpsnr\n",
    "\n",
    "    best_validation_psnr = run_test_step(0)\n",
    "    print('** initial val psnr ', best_validation_psnr)\n",
    "    best_t = None\n",
    "    for i in range(FLAGS.num_epochs):\n",
    "        print('epoch', i)\n",
    "        tpsnr = 0.0\n",
    "        for j, (c2w, im_gt) in tqdm(enumerate(zip(train_c2w, train_gt)), total=n_train_imgs):\n",
    "            im = r.render_persp(c2w, height=H, width=W, fx=focal, cuda=True)\n",
    "            im_gt_ten = im_gt.to(device=device)\n",
    "            im = torch.clamp(im, 0.0, 1.0)\n",
    "            mse = ((im - im_gt_ten) ** 2).mean()\n",
    "            im_gt_ten = None\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            t.data.grad = None  # This helps save memory weirdly enough\n",
    "            mse.backward()\n",
    "            #  print('mse', mse, t.data.grad.min(), t.data.grad.max())\n",
    "            optimizer.step()\n",
    "            #  t.data.data -= eta * t.data.grad\n",
    "            psnr = -10.0 * np.log(mse.detach().cpu()) / np.log(10.0)\n",
    "            tpsnr += psnr.item()\n",
    "        tpsnr /= n_train_imgs\n",
    "        print('** train_psnr', tpsnr)\n",
    "\n",
    "        if i % FLAGS.val_interval == FLAGS.val_interval - 1 or i == FLAGS.num_epochs - 1:\n",
    "            validation_psnr = run_test_step(i + 1)\n",
    "            print('** val psnr ', validation_psnr, 'best', best_validation_psnr)\n",
    "            if validation_psnr > best_validation_psnr:\n",
    "                best_validation_psnr = validation_psnr\n",
    "                best_t = t.clone(device='cpu')  # SVOX 0.2.22\n",
    "                print('')\n",
    "            elif not FLAGS.continue_on_decrease:\n",
    "                print('Stop since overfitting')\n",
    "                break\n",
    "    if not FLAGS.nosave:\n",
    "        if best_t is not None:\n",
    "            print('Saving best model to', FLAGS.output)\n",
    "            best_t.save(FLAGS.output, compress=False)\n",
    "        else:\n",
    "            print('Did not improve upon initial model')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(main)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}